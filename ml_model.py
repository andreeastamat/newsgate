# -*- coding: utf-8 -*-
"""ml_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NDSL9_SHEFgCcCW8JqOkoGpyQ9ytqnNH

## **Imports**
"""

from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
from mlxtend.plotting import plot_confusion_matrix
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import pickle
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report
import regex as reg
import warnings

warnings.filterwarnings('ignore')

nltk.download('punkt')
nltk.download('stopwords')

"""## **Loading the dataset**"""

df = pd.read_csv(r'train.csv')
df.text = df.text.astype(str)

"""## **Number of entries per each label**"""

_ = plt.bar([0, 1], [df[df.label == 1].shape[0], df[df.label == 0].shape[0]])
plt.xticks([0, 1], ['Fals', 'Real'])
plt.xlabel('Categorie')
plt.ylabel('Frecventa')
plt.title('Inregistrari per categorie')
plt.show()

"""## **Preprocessing the data for an accurate model**"""

cached_stopwords = stopwords.words('english')


def replace_spec(text):
    regex = r'[^a-zA-z0-9/s]'
    text = reg.sub(regex, ' ', text)
    return text


def process_text(text):
    text = text.lower()
    text = replace_spec(text)

    text_list = str.split(text)

    final_text = []

    for item in text_list:
        if item not in cached_stopwords:
            final_text.append(item)

    return " ".join(final_text)


df['text'] = df.text.apply(process_text)

"""## **Finding the best parameters for the model and fitting the data to the model**"""

X = df.text
y = df.label

text_classifier = Pipeline([('vect', TfidfVectorizer(tokenizer=word_tokenize, lowercase=False)),
                            ('clf', SVC(probability=True))])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

text_classifier = text_classifier.fit(X_train, y_train)
prediction = text_classifier.predict(X_test)

print(classification_report(y_test, prediction, target_names=['Fake', 'Real']))

"""## **Printing the confusion matrix for the Support Vector Machine classifier**"""

cm = confusion_matrix(y_test, prediction)
plot_confusion_matrix(conf_mat=cm, show_absolute=True,
                      show_normed=True,
                      colorbar=True)

"""## **Saving the best model as a pickle file**"""

pkl_filename = "SVM_Model.pkl"

with open(pkl_filename, 'wb') as file:
    pickle.dump(text_classifier, file)
